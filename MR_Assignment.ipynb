{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanketAinapure/Transformer/blob/main/MR_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers opencv-python numpy tqdm onnx onnxruntime seaborn matplotlib\n",
        "!pip install simplejson\n",
        "!pip install einops\n",
        "!pip install timm\n",
        "!pip install psutil\n",
        "!pip install scikit-learn\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "rQT6I-ojYnR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "78a1ce54-66f7-4a64-f02c-12eacf897c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.6)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 onnxruntime-1.21.0\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (3.20.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQpJVZj0QXwC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import AutoImageProcessor, TimesformerForVideoClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciHImm_AQXwF"
      },
      "outputs": [],
      "source": [
        "class HARDataset(Dataset):\n",
        "    def __init__(self, root_dir, processor, num_frames=8):\n",
        "        self.root_dir = root_dir\n",
        "        self.processor = processor\n",
        "        self.num_frames = num_frames\n",
        "        self.classes = sorted(os.listdir(root_dir))  # Class names\n",
        "        self.video_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            for video_name in os.listdir(class_path):\n",
        "                video_path = os.path.join(class_path, video_name)\n",
        "                self.video_paths.append(video_path)\n",
        "                self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_paths)\n",
        "\n",
        "    def load_video_frames(self, video_path):\n",
        "        \"\"\"Extract `num_frames` evenly spaced frames from the video\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_indices = np.linspace(0, frame_count - 1, self.num_frames, dtype=int)\n",
        "        frames = []\n",
        "\n",
        "        for idx in frame_indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # If not enough frames, duplicate the last frame\n",
        "        if len(frames) < self.num_frames:\n",
        "            frames += [frames[-1]] * (self.num_frames - len(frames))\n",
        "\n",
        "        return frames\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        frames = self.load_video_frames(video_path)\n",
        "        inputs = self.processor(frames, return_tensors=\"pt\")\n",
        "        pixel_values = inputs[\"pixel_values\"].squeeze(0)  # Shape: (num_frames, C, H, W)\n",
        "\n",
        "        return pixel_values, torch.tensor(label, dtype=torch.long)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DB2q8xfAk3GQ",
        "outputId": "c10a9dd0-45c7-449c-ddef-858a2571af1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92d6a889-071f-400c-8b10-c3d628f9a9b8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92d6a889-071f-400c-8b10-c3d628f9a9b8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sanketainapure\",\"key\":\"50fdd54693e572871e7c6034dd32b4d5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "9rY2nowJlWzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sharjeelmazhar/human-activity-recognition-video-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFcXTQ4glsyD",
        "outputId": "0f9b3f6e-42c5-40a8-8053-43958f612497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/sharjeelmazhar/human-activity-recognition-video-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading human-activity-recognition-video-dataset.zip to /content\n",
            "100% 14.8G/14.8G [03:32<00:00, 113MB/s] \n",
            "100% 14.8G/14.8G [03:32<00:00, 74.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip human-activity-recognition-video-dataset.zip -d ./data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a0i2cM1Am_1a",
        "outputId": "77077154-31b2-4e2a-c2bf-4cf4a3dc94f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  human-activity-recognition-video-dataset.zip\n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Clapping/Clapping (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (147).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Meet and Split/Meet and Split (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (147).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (148).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (149).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (150).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (151).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (152).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (153).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (154).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (155).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (156).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Sitting/Sitting (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (147).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (148).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (149).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (150).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (151).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (152).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (153).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (154).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (155).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (156).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (157).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (158).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (159).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (160).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (161).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (162).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (163).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (164).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (165).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (166).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (167).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (168).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (169).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (170).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (171).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (172).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (173).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (174).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Standing Still/Standing Still (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (147).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (148).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (149).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (150).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (151).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (152).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (153).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (154).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (155).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (156).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (157).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (158).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (159).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (160).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (161).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (162).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (163).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (164).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (165).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (166).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (167).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (168).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (169).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (170).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (171).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (172).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (173).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (174).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (175).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (176).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Reading Book/Walking While Reading Book (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking While Using Phone/Walking While Using Phone (99).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (1).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (10).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (100).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (101).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (102).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (103).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (104).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (105).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (106).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (107).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (108).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (109).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (11).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (110).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (111).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (112).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (113).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (114).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (115).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (116).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (117).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (118).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (119).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (12).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (120).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (121).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (122).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (123).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (124).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (125).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (126).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (127).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (128).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (129).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (13).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (130).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (131).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (132).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (133).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (134).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (135).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (136).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (137).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (138).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (139).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (14).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (140).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (141).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (142).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (143).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (144).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (145).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (146).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (147).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (148).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (149).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (15).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (150).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (151).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (152).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (153).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (154).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (155).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (156).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (157).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (158).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (159).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (16).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (160).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (161).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (162).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (163).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (164).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (165).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (166).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (167).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (168).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (169).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (17).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (170).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (171).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (18).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (19).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (2).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (20).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (21).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (22).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (23).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (24).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (25).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (26).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (27).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (28).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (29).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (3).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (30).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (31).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (32).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (33).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (34).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (35).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (36).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (37).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (38).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (39).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (4).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (40).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (41).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (42).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (43).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (44).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (45).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (46).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (47).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (48).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (49).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (5).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (50).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (51).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (52).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (53).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (54).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (55).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (56).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (57).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (58).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (59).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (6).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (60).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (61).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (62).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (63).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (64).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (65).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (66).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (67).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (68).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (69).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (7).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (70).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (71).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (72).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (73).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (74).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (75).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (76).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (77).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (78).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (79).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (8).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (80).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (81).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (82).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (83).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (84).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (85).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (86).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (87).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (88).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (89).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (9).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (90).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (91).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (92).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (93).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (94).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (95).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (96).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (97).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (98).mp4  \n",
            "  inflating: ./data/Human Activity Recognition - Video Dataset/Walking/Walking (99).mp4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiX33buuQXwF",
        "outputId": "401cf660-9beb-4980-c374-1db44b51fd68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded: 779 Train, 334 Test\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/data/Human Activity Recognition - Video Dataset\"\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "\n",
        "# Create dataset\n",
        "full_dataset = HARDataset(dataset_path, processor, num_frames=8)\n",
        "\n",
        "# Split dataset (70% train, 30% test)\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "print(f\"Dataset Loaded: {len(train_dataset)} Train, {len(test_dataset)} Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIA9ZhuRQXwG",
        "outputId": "0dabe720-00ca-4601-a01d-221d1ee74ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "603b8abb725243a28894f47f23c85785",
            "d222fe1000d549f68a1df7a8f1d91719",
            "fb69f1564ff44049a7e66c3f9d952c16",
            "81602a5b61dd4ae994b11adcc119ad98",
            "135c68b9379944aa830db79ef4b01371",
            "06c01ce9f36d4dc08405687b0fc357f8",
            "63bc5f1768824ad68f2f92faf6e00365",
            "e0d2e78b052540cea45c424c2cd3c806",
            "26e625ede9434c01bab40d779b3e8c3b",
            "aa561e1e1acb402c908d33e2a19accf9",
            "79fd0dc19c824bb583e0be764d659a40",
            "737e3f20dbd04bcfa18b17803d7d5b21",
            "21f861c7f48446c4a9648dc01555e198",
            "9b37ddb4266f4056b0e60b472b4955b5",
            "a52f949adace4ded87198d435f2aaf97",
            "a8adbadf7aa242a48ecad32abe0412b6",
            "942836007ecd48299150c21a6fe0e74b",
            "a8ce9de5362145dca3d69ca8e7ad2e88",
            "22e0cca0db774153a32d5f19b24d4120",
            "7dd5e42f0d0b472eabfeddb6f2560834",
            "792c569a1d0a4df4aba187dba46d26cd",
            "e0d9ddf5a7fd43a78440cb6140018812",
            "fdde266c868f4958b4dad54e901459d9",
            "3a6dbac5caad46d08188bd824e02b053",
            "15a1a7426ca943fd9bba6b91077e351b",
            "68bc2a98f52b4ebf85d008aa9d317c38",
            "d10e27bc8b464f25945da7a2765b8d2c",
            "cb119a4b66364b7ebea75a89fbf1cd85",
            "a3d84a6805f44238a9a9dcbf14267f4e",
            "ae29b5b5ca37482cb5729066ab7616bb",
            "03e46b486f8442a8bb55b8507b1eeaec",
            "7f8637fab3bf4698a46e12a1be88ae91",
            "c3fbb58b092942a69f91d600c8c42d42"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/22.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "603b8abb725243a28894f47f23c85785"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/486M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "737e3f20dbd04bcfa18b17803d7d5b21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/486M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdde266c868f4958b4dad54e901459d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TimesformerForVideoClassification(\n",
              "  (timesformer): TimesformerModel(\n",
              "    (embeddings): TimesformerEmbeddings(\n",
              "      (patch_embeddings): TimesformerPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (time_drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): TimesformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x TimesformerLayer(\n",
              "          (drop_path): Identity()\n",
              "          (attention): TimeSformerAttention(\n",
              "            (attention): TimesformerSelfAttention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TimesformerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TimesformerIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TimesformerOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (temporal_attention): TimeSformerAttention(\n",
              "            (attention): TimesformerSelfAttention(\n",
              "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): TimesformerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model = TimesformerForVideoClassification.from_pretrained(\n",
        "    \"facebook/timesformer-base-finetuned-k400\",\n",
        "    num_labels=len(full_dataset.classes), ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Send model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gECrU0k2QXwG",
        "outputId": "e56e01ec-07ea-4c8d-e8b7-b308231597f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Batch [0/195], Loss: 1.8091\n",
            "Epoch [1/3], Batch [10/195], Loss: 2.1582\n",
            "Epoch [1/3], Batch [20/195], Loss: 2.0322\n",
            "Epoch [1/3], Batch [30/195], Loss: 0.7627\n",
            "Epoch [1/3], Batch [40/195], Loss: 0.6760\n",
            "Epoch [1/3], Batch [50/195], Loss: 1.0571\n",
            "Epoch [1/3], Batch [60/195], Loss: 0.8249\n",
            "Epoch [1/3], Batch [70/195], Loss: 0.5592\n",
            "Epoch [1/3], Batch [80/195], Loss: 0.5881\n",
            "Epoch [1/3], Batch [90/195], Loss: 0.3520\n",
            "Epoch [1/3], Batch [100/195], Loss: 0.6747\n",
            "Epoch [1/3], Batch [110/195], Loss: 0.2517\n",
            "Epoch [1/3], Batch [120/195], Loss: 0.2968\n",
            "Epoch [1/3], Batch [130/195], Loss: 0.1834\n",
            "Epoch [1/3], Batch [140/195], Loss: 0.0708\n",
            "Epoch [1/3], Batch [150/195], Loss: 0.1503\n",
            "Epoch [1/3], Batch [160/195], Loss: 0.0921\n",
            "Epoch [1/3], Batch [170/195], Loss: 0.1650\n",
            "Epoch [1/3], Batch [180/195], Loss: 0.0769\n",
            "Epoch [1/3], Batch [190/195], Loss: 0.1080\n",
            "Epoch [1/3] Completed - Avg Loss: 0.6572\n",
            "Test Accuracy: 99.10%\n",
            "New Best Model Saved! Accuracy: 99.10%\n",
            "Epoch [2/3], Batch [0/195], Loss: 0.0965\n",
            "Epoch [2/3], Batch [10/195], Loss: 0.0868\n",
            "Epoch [2/3], Batch [20/195], Loss: 0.0386\n",
            "Epoch [2/3], Batch [30/195], Loss: 0.1072\n",
            "Epoch [2/3], Batch [40/195], Loss: 0.0284\n",
            "Epoch [2/3], Batch [50/195], Loss: 0.0239\n",
            "Epoch [2/3], Batch [60/195], Loss: 0.0328\n",
            "Epoch [2/3], Batch [70/195], Loss: 0.0437\n",
            "Epoch [2/3], Batch [80/195], Loss: 0.0620\n",
            "Epoch [2/3], Batch [90/195], Loss: 0.0703\n",
            "Epoch [2/3], Batch [100/195], Loss: 0.0289\n",
            "Epoch [2/3], Batch [110/195], Loss: 0.0233\n",
            "Epoch [2/3], Batch [120/195], Loss: 0.0345\n",
            "Epoch [2/3], Batch [130/195], Loss: 0.0294\n",
            "Epoch [2/3], Batch [140/195], Loss: 0.0249\n",
            "Epoch [2/3], Batch [150/195], Loss: 0.0292\n",
            "Epoch [2/3], Batch [160/195], Loss: 0.0359\n",
            "Epoch [2/3], Batch [170/195], Loss: 0.0274\n",
            "Epoch [2/3], Batch [180/195], Loss: 0.0366\n",
            "Epoch [2/3], Batch [190/195], Loss: 0.0152\n",
            "Epoch [2/3] Completed - Avg Loss: 0.0517\n",
            "Test Accuracy: 100.00%\n",
            "New Best Model Saved! Accuracy: 100.00%\n",
            "Epoch [3/3], Batch [0/195], Loss: 0.0197\n",
            "Epoch [3/3], Batch [10/195], Loss: 0.0356\n",
            "Epoch [3/3], Batch [20/195], Loss: 0.0131\n",
            "Epoch [3/3], Batch [30/195], Loss: 0.0277\n",
            "Epoch [3/3], Batch [40/195], Loss: 0.0187\n",
            "Epoch [3/3], Batch [50/195], Loss: 0.0166\n",
            "Epoch [3/3], Batch [60/195], Loss: 0.0166\n",
            "Epoch [3/3], Batch [70/195], Loss: 0.0161\n",
            "Epoch [3/3], Batch [80/195], Loss: 0.0337\n",
            "Epoch [3/3], Batch [90/195], Loss: 0.0129\n",
            "Epoch [3/3], Batch [100/195], Loss: 0.0150\n",
            "Epoch [3/3], Batch [110/195], Loss: 0.0159\n",
            "Epoch [3/3], Batch [120/195], Loss: 0.0196\n",
            "Epoch [3/3], Batch [130/195], Loss: 0.0108\n",
            "Epoch [3/3], Batch [140/195], Loss: 0.0145\n",
            "Epoch [3/3], Batch [150/195], Loss: 0.0087\n",
            "Epoch [3/3], Batch [160/195], Loss: 0.0167\n",
            "Epoch [3/3], Batch [170/195], Loss: 0.0081\n",
            "Epoch [3/3], Batch [180/195], Loss: 0.0079\n",
            "Epoch [3/3], Batch [190/195], Loss: 0.0095\n",
            "Epoch [3/3] Completed - Avg Loss: 0.0165\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "scaler = torch.amp.GradScaler(\"cuda\")  # For mixed precision training\n",
        "\n",
        "num_epochs = 3  # Change for longer training\n",
        "\n",
        "best_accuracy = 0.0  # Track the best accuracy\n",
        "\n",
        "#track metrics\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (pixel_values, labels) in enumerate(train_loader):\n",
        "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(\"cuda\"):  # Mixed precision forward pass\n",
        "            outputs = model(pixel_values)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Completed - Avg Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for pixel_values, labels in test_loader:\n",
        "            pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(pixel_values)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), \"best_timesformer_har.pth\")\n",
        "        print(f\"New Best Model Saved! Accuracy: {best_accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73zZV6dnQXwH"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for pixel_values, labels in test_loader:\n",
        "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(pixel_values)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "#traning loss curve\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), train_losses, marker='o', label=\"train loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training loss v/s epochs\")\n",
        "plt.legend()\n",
        "\n",
        "#testing loss curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), test_accuracies, marker='s', label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy percentage\")\n",
        "plt.title(\"Test Accuracy v/s epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qT1DtLklUa1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "\n",
        "class_names = full_dataset.classes\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylable(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mg0oninLx_b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision, Recall, F1 score per class\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "x = range(len(class_names))\n",
        "plt.bar(x, precision, width=0.3, label=\"Precision\")\n",
        "plt.bar([i + 0.3 for i in x], recall, width=0.3, label=\"Recall\")\n",
        "plt.bar([i + 0.6 for i in x], f1, width=0.3, label=\"F1-Score\")\n",
        "plt.xticks([i + 0.3 for i in x], class_names, rotation=45)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Precision, Recall, F1-Score Per Class\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pt0iuM6Vx-8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3756AaUQXwH",
        "outputId": "7fed38dd-edff-4b94-806e-3466d7d14b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"timesformer_har.pth\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4CgSne9QXwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10983da-1a30-45ce-f911-e362154f4c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/timesformer/modeling_timesformer.py:104: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if embeddings.size(1) != self.position_embeddings.size(1):\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/timesformer/modeling_timesformer.py:133: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_frames != self.time_embeddings.size(1):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model exported as ONNX successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch.onnx\n",
        "\n",
        "# Dummy input with correct shape (batch_size=1, num_frames=8, C=3, H=224, W=224)\n",
        "dummy_input = torch.randn(1, 8, 3, 224, 224).to(device)\n",
        "\n",
        "# Export model to ONNX\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    \"best_timesformer_har.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=12,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={           # Allow variable batch size\n",
        "        \"input\": {0: \"batch_size\"},\n",
        "        \"output\": {0: \"batch_size\"}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Model exported as ONNX successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "603b8abb725243a28894f47f23c85785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d222fe1000d549f68a1df7a8f1d91719",
              "IPY_MODEL_fb69f1564ff44049a7e66c3f9d952c16",
              "IPY_MODEL_81602a5b61dd4ae994b11adcc119ad98"
            ],
            "layout": "IPY_MODEL_135c68b9379944aa830db79ef4b01371"
          }
        },
        "d222fe1000d549f68a1df7a8f1d91719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c01ce9f36d4dc08405687b0fc357f8",
            "placeholder": "​",
            "style": "IPY_MODEL_63bc5f1768824ad68f2f92faf6e00365",
            "value": "config.json: 100%"
          }
        },
        "fb69f1564ff44049a7e66c3f9d952c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d2e78b052540cea45c424c2cd3c806",
            "max": 22723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e625ede9434c01bab40d779b3e8c3b",
            "value": 22723
          }
        },
        "81602a5b61dd4ae994b11adcc119ad98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa561e1e1acb402c908d33e2a19accf9",
            "placeholder": "​",
            "style": "IPY_MODEL_79fd0dc19c824bb583e0be764d659a40",
            "value": " 22.7k/22.7k [00:00&lt;00:00, 66.6kB/s]"
          }
        },
        "135c68b9379944aa830db79ef4b01371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c01ce9f36d4dc08405687b0fc357f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63bc5f1768824ad68f2f92faf6e00365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0d2e78b052540cea45c424c2cd3c806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e625ede9434c01bab40d779b3e8c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa561e1e1acb402c908d33e2a19accf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fd0dc19c824bb583e0be764d659a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "737e3f20dbd04bcfa18b17803d7d5b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21f861c7f48446c4a9648dc01555e198",
              "IPY_MODEL_9b37ddb4266f4056b0e60b472b4955b5",
              "IPY_MODEL_a52f949adace4ded87198d435f2aaf97"
            ],
            "layout": "IPY_MODEL_a8adbadf7aa242a48ecad32abe0412b6"
          }
        },
        "21f861c7f48446c4a9648dc01555e198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942836007ecd48299150c21a6fe0e74b",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ce9de5362145dca3d69ca8e7ad2e88",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9b37ddb4266f4056b0e60b472b4955b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e0cca0db774153a32d5f19b24d4120",
            "max": 486348721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dd5e42f0d0b472eabfeddb6f2560834",
            "value": 486348721
          }
        },
        "a52f949adace4ded87198d435f2aaf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792c569a1d0a4df4aba187dba46d26cd",
            "placeholder": "​",
            "style": "IPY_MODEL_e0d9ddf5a7fd43a78440cb6140018812",
            "value": " 486M/486M [00:02&lt;00:00, 224MB/s]"
          }
        },
        "a8adbadf7aa242a48ecad32abe0412b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942836007ecd48299150c21a6fe0e74b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ce9de5362145dca3d69ca8e7ad2e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22e0cca0db774153a32d5f19b24d4120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd5e42f0d0b472eabfeddb6f2560834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "792c569a1d0a4df4aba187dba46d26cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d9ddf5a7fd43a78440cb6140018812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdde266c868f4958b4dad54e901459d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6dbac5caad46d08188bd824e02b053",
              "IPY_MODEL_15a1a7426ca943fd9bba6b91077e351b",
              "IPY_MODEL_68bc2a98f52b4ebf85d008aa9d317c38"
            ],
            "layout": "IPY_MODEL_d10e27bc8b464f25945da7a2765b8d2c"
          }
        },
        "3a6dbac5caad46d08188bd824e02b053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb119a4b66364b7ebea75a89fbf1cd85",
            "placeholder": "​",
            "style": "IPY_MODEL_a3d84a6805f44238a9a9dcbf14267f4e",
            "value": "model.safetensors: 100%"
          }
        },
        "15a1a7426ca943fd9bba6b91077e351b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae29b5b5ca37482cb5729066ab7616bb",
            "max": 486296528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03e46b486f8442a8bb55b8507b1eeaec",
            "value": 486296528
          }
        },
        "68bc2a98f52b4ebf85d008aa9d317c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f8637fab3bf4698a46e12a1be88ae91",
            "placeholder": "​",
            "style": "IPY_MODEL_c3fbb58b092942a69f91d600c8c42d42",
            "value": " 486M/486M [00:03&lt;00:00, 221MB/s]"
          }
        },
        "d10e27bc8b464f25945da7a2765b8d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb119a4b66364b7ebea75a89fbf1cd85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d84a6805f44238a9a9dcbf14267f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae29b5b5ca37482cb5729066ab7616bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e46b486f8442a8bb55b8507b1eeaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f8637fab3bf4698a46e12a1be88ae91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3fbb58b092942a69f91d600c8c42d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}